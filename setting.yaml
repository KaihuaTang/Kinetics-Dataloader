rng_seed: 1                          # Note that non-determinism may still be present due to non-deterministic operator implementations in GPU operator libraries.
shard_id: 0                          # The index of the current machine.

data:
  path_to_anno_dir: ''               # The path to the annotation directory.
  use_offset_sampling: False         # If True, perform stride length uniform temporal sampling.
  train_scales: [256, 320]           # The spatial augmentation jitter scales for training.
  train_crop_size: 224               # The spatial crop size for training.
  test_crop_size: 256                # The spatial crop size for testing.
  target_fps: 30                     # Input videos may has different fps, convert it to the target video fps before frame sampling.
  num_frames: 8                      # The number of frames of the input clip.
  sampling_rate: 8                   # The video sampling rate of the input clip.
  decoding_backend: 'pyav'           # Decoding backend, options include `pyav` or `torchvision`
  mean: [0.45, 0.45, 0.45]           # The mean value of the video raw pixels across the R G B channels.
  std:  [0.225, 0.225, 0.225]        # The std value of the video raw pixels across the R G B channels.
  random_flip: True                  # If True, perform random horizontal flip on the video frames during training.
  

data_loader:
  num_workers: 8                     # Number of data loader workers per training process.
  pin_memory: True                   # Load data to pinned host memory.


train:
  dataset: 'kinetics'                # Dataset.
  batch_size: 64                     # Total mini-batch size.
  num_ensemble_views: 1              # Number of clips to sample from a video uniformly for aggregating the prediction results.
  num_spatial_crops: 1               # Number of crops to sample from a frame spatially for aggregating the prediction results.


test:
  dataset: 'kinetics'       # Dataset
  batch_size: 8             # Total mini-batch size
  num_ensemble_views: 10    # Number of clips to sample from a video uniformly for aggregating the prediction results.
  num_spatial_crops: 3      # Number of crops to sample from a frame spatially for aggregating the prediction results.
  

multigrid:
  epoch_factor: 1.5           # Multigrid training allows us to train for more epochs with fewer iterations. The default setting in paper trains for 1.5x more epochs than baseline.
  short_cycle: False          # Enable short cycles.
  short_cycle_factors: [0.5, 0.7071067811865476]   # Short cycle additional spatial dimensions relative to the default crop size.  [0.5, 0.5 ** 0.5]

model:
  arch: 'default'                                                       # Model architecture.
  model_name: 'default'                                                 # Model name

slowfast:
  alpha: 8                     # Corresponds to the frame rate reduction ratio, $\alpha$ between the Slow and Fast pathways.
